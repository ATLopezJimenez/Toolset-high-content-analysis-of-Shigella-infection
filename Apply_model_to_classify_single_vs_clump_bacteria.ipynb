{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2Ds3RLKvful"
      },
      "source": [
        "**General description**\n",
        "\n",
        "This notebook has been developed by Ana Teresa Lopez Jimenez @ LSHTM\n",
        "\n",
        "It has been used in the preprint: High-content superresolution microscopy and deep learning assisted analysis reveals host and bacterial heterogeneity during Shigella infection. Ana T. López-Jiménez, Dominik Brokatzky, Kamla Pillay, Tyrese Williams, Gizem Özbaykal Güler and Serge Mostowy (2024)\n",
        "\n",
        "\n",
        "This notebook allows to classify single vs. clumped rod-shape bacteria."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preparation, import of required packages**"
      ],
      "metadata": {
        "id": "I6xMoLkSxpGz"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCIyh74iVsS1"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjgR5wBvCVMB"
      },
      "source": [
        "!pip install pyyaml h5py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQgRrZg4wPAs"
      },
      "source": [
        "**Data loading from Google drive**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eIt-lBxwYPj"
      },
      "source": [
        "from google.colab import drive\n",
        "root = '/content/gdrive/'\n",
        "drive.mount( root )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_n4bLb7wY8V"
      },
      "source": [
        "singles_dir_path = r'/My Drive/folder' # write here directory where files to be analysed are\n",
        "os.makedirs(root+singles_dir_path, exist_ok=True)\n",
        "os.listdir(root+singles_dir_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChvyWq5pxxAH"
      },
      "source": [
        "**Importing the Model**\n",
        "\n",
        "For this step, it is required to add the trained model \"model_classification_single_vs_clump.hdf5\" to Google drive, and specify the correct folder here below to retrieve it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqMjTzbjxzf7"
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense,Activation, Dropout, Conv2D, MaxPooling2D, Flatten, BatchNormalization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjomGGHun4zj"
      },
      "source": [
        "\n",
        "new_model = tf.keras.models.load_model('/content/gdrive/My Drive/folder/model_classification_single_vs_clump.hdf5') # Specify the folder containing the model\n",
        "new_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGu-iiKo6N1H"
      },
      "source": [
        "new_model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04v0OL4fwzqj"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "IMG_SHAPE  = 128 # Our training data consists of images with width of 128 pixels and height of 128 pixels."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0BUzNDl7tG2"
      },
      "source": [
        "image_gen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "image_data_gen = image_gen.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                                 directory=root+singles_dir_path,\n",
        "                                                 target_size=(IMG_SHAPE, IMG_SHAPE),\n",
        "                                                 color_mode=\"grayscale\",\n",
        "                                                 class_mode='binary',\n",
        "                                                 shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Applying the model and saving results**\n",
        "\n",
        "In this step the model will be applied to generate predictions (0, 1).\n",
        "The results can be saved as a .txt document in the folder specificied here below."
      ],
      "metadata": {
        "id": "5RwVRWHFLn9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_data = []\n",
        "file_names = image_data_gen.filenames\n",
        "predict_x=new_model.predict(image_data_gen)\n",
        "classes_x=[1 * (x[0]>=0.5) for x in predict_x]\n",
        "\n",
        "new_data = np.array([file_names, classes_x]).T\n",
        "print(new_data)\n",
        "np.savetxt('/content/gdrive/My Drive/folder/Results_singles.txt', new_data, fmt='%s') # Specify here the output folder\n"
      ],
      "metadata": {
        "id": "4Nr4OmRwoRXA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}